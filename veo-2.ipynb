{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a331300-5ff3-4219-83c0-ce11703cc9e1",
   "metadata": {},
   "source": [
    "Copyright 2024 Google, LLC. This software is provided as-is,\n",
    "without warranty or representation for any use or purpose. Your\n",
    "use of it is subject to your agreement with Google.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "\n",
    "# How To Use Vertex Veo for Text to Video and Imange to Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34429b82-078c-4107-827d-8aaed4ab1121",
   "metadata": {},
   "source": [
    "This notebook outlines how to interact with Vertex Veo model to create dynamic video content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed54ec-9f36-40af-8d2e-c6fd32a76222",
   "metadata": {},
   "source": [
    "## Prepare the python development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ce888-8c52-476b-96d0-7f65cb259f8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, let's identify any project specific variables to customize this notebook to your GCP environment. At a minimum, change YOUR_PROJECT_ID and YOUR_BUCKET to reflect your own GCP project info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205088b5-6d5b-46dd-9d77-a8352eac630b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"YOUR_PROJECT_ID\"\n",
    "location = \"global\"\n",
    "region = \"us-central1\"\n",
    "\n",
    "gcs_bucket = \"YOUR_GCS_BUCKET\"\n",
    "output_gcs_uri = f'''gs://{gcs_bucket}'''\n",
    "\n",
    "local_tmp_folder_1 = \"./tmp/vid1\"\n",
    "local_tmp_folder_2 = \"./tmp/vid2\"\n",
    "local_tmp_folder_3 = \"./tmp/vid3\"\n",
    "\n",
    "source_image = \"source_image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92738a-045b-48a4-ab0e-1d98fad2089a",
   "metadata": {},
   "source": [
    "Install any needed python modules from our requirements.txt file. Most Vertex Workbench environments include all the packages we'll be using, but if you are using an external Jupyter Notebook or require any additional packages for your own needs, you can simply add them to the included requirements.txt file an run the folloiwng commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69175b8-63c4-4b5a-837d-055743c0b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install --upgrade google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b2ce7-0277-4ada-9648-34c67774bfd2",
   "metadata": {},
   "source": [
    "Now we will import all required modules. For our purpose, we will be utilizing the following:\n",
    "\n",
    "- google.auth - Provides authentication access to the Google API's, such as imagegeneration:predict\n",
    "- PIL - An easy to use Python image library to help build the background for our banner and perform image layering\n",
    "- io - Core python libray used to work with I/O. We will use this to help convert strings to byte objects for PIL\n",
    "- base64 - Imagen API requests return generated or edited images as base64-encoded strings. This module will help us decode this data to an image file\n",
    "- requests - This module will allow us to interact directly with Imagen over the REST API. \n",
    "- json - Python module used to interact with JSON data. Imagen returns results in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e15897-0cb0-4173-9b91-17270a10b989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.auth.transport.requests\n",
    "import google.auth\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "from IPython.display import clear_output, HTML, Video\n",
    "import asyncio\n",
    "import contextlib\n",
    "import itertools\n",
    "import yaml\n",
    "import cv2\n",
    "import ffmpeg\n",
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import GenerateVideosConfig, HttpOptions, Part\n",
    "from google.genai.types import Image as genImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4707e1-1b1c-4fd5-bada-c4665b867d47",
   "metadata": {},
   "source": [
    "## Function Junction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d162f-ff9c-4bf2-845f-7ec0336da35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_file_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the GCS bucket (simplified version).\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file.jpg\"\n",
    "    # destination_blob_name = \"storage-object-name.jpg\"\n",
    "\n",
    "    # Initialize the GCS client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Get the bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Create a new blob (or refer to an existing one)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Upload the local file to GCS\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to gs://{bucket_name}/{destination_blob_name}.\"\n",
    "    )\n",
    "    \n",
    "    return f'gs://{bucket_name}/{destination_blob_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e3a91-ad89-4b4a-be39-fbae3240fcb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_file_from_uri(uri, local_directory_path):\n",
    "    \"\"\"\n",
    "    Downloads a file from Google Cloud Storage using a URI,\n",
    "    saving it to the specified local directory with its original filename (without subfolders).\n",
    "\n",
    "    Args:\n",
    "        uri: The GCS URI (e.g., gs://my-bucket/sub_folder/my-file.txt).\n",
    "        ocal_directory_path: The directory where the file should be saved locally.\n",
    "                          The filename will be extracted from the GCS object name.\n",
    "    Raises:\n",
    "        ValueError: If the URI is malformed.\n",
    "        google.cloud.exceptions.NotFound: If the bucket or blob does not exist.\n",
    "    \"\"\"\n",
    "    if not uri.startswith(\"gs://\"):\n",
    "        raise ValueError(f\"Invalid GCS URI: '{uri}'. Must start with 'gs://'.\")\n",
    "\n",
    "    # Parse the URI\n",
    "    try:\n",
    "        # Splitting \"gs://bucket/object/path\" into \"bucket\" and \"object/path\"\n",
    "        path_without_scheme = uri[5:] # Remove \"gs://\"\n",
    "        bucket_name, object_name = path_without_scheme.split('/', 1)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Invalid GCS URI format: '{uri}'. Expected gs://bucket_name/object_name.\")\n",
    "\n",
    "    if not object_name:\n",
    "        raise ValueError(f\"Invalid GCS URI: '{uri}'. Object name cannot be empty.\")\n",
    "\n",
    "    # Extract the base filename from the object_name\n",
    "    # e.g., if object_name is \"sub_folder/file.mp4\", base_filename will be \"file.mp4\"\n",
    "    base_filename = os.path.basename(object_name)\n",
    "    if not base_filename: # Handles cases like \"gs://bucket/folder/\"\n",
    "        raise ValueError(f\"Could not determine filename from object: {object_name}\")\n",
    "\n",
    "\n",
    "    # Ensure the local directory exists\n",
    "    os.makedirs(local_directory_path, exist_ok=True)\n",
    "\n",
    "    # Construct the full local path for saving the file\n",
    "    full_local_save_path = os.path.join(local_directory_path, base_filename)\n",
    "\n",
    "    # Create a client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    try:\n",
    "        # Get a bucket and blob object\n",
    "        bucket = storage_client.bucket(bucket_name) # More direct way to get bucket reference\n",
    "        blob = bucket.blob(object_name)\n",
    "\n",
    "        if not blob.exists():\n",
    "            raise NotFound(f\"Blob {object_name} not found in bucket {bucket_name}.\")\n",
    "\n",
    "        # Download the file\n",
    "        print(f\"Downloading {uri} to {full_local_save_path}...\")\n",
    "        blob.download_to_filename(full_local_save_path)\n",
    "        print(f\"Successfully downloaded to {full_local_save_path}\")\n",
    "    \n",
    "        return full_local_save_path\n",
    "\n",
    "    except NotFound as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        raise # Re-raise the exception if you want the caller to handle it\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449038c-9d93-4729-b835-7429d1c8972f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_last_frame(video_path, output_path):\n",
    "    \"\"\"Extracts the last frame from a video and saves it as an image.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the input video file.\n",
    "        output_path: Path to save the output image file.\n",
    "    \"\"\"\n",
    "    print(video_path)\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    if not video_capture.isOpened():\n",
    "        raise Exception(f\"Could not open video file: {video_path}\")\n",
    "\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Ensure the frame number is valid\n",
    "    if total_frames > 0:\n",
    "      video_capture.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
    "    ret, last_frame = video_capture.read()\n",
    "\n",
    "    if ret:\n",
    "        cv2.imwrite(output_path, last_frame)\n",
    "        print(f\"Last frame saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the last frame.\")\n",
    "\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b2668-962a-42da-b92b-4932f224bb0d",
   "metadata": {},
   "source": [
    "## Authenticate to the Vertex AI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57a2c4-d51a-42b8-b0c7-24aced49d64b",
   "metadata": {},
   "source": [
    "Our Vertex Workbench instance is configured to use a specified service account that has IAM access to the Veo API. The following two secitons will allow us to generate the access token we will pass as an authorization bearer token later in the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94ec73-538a-47cb-8e7e-407d3af35b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(\n",
    "    vertexai=True, project=project_id, location=region\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c6434-8468-4e0c-a03f-6b1ed7d3e943",
   "metadata": {},
   "source": [
    "## Inspect the source image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ff08f-000d-4179-a5f5-14ae90c73579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(source_image, \"rb\") as f:\n",
    "    encoded_base_image = base64.b64encode(f.read())\n",
    "B64_BASE_IMAGE = encoded_base_image.decode('utf-8')\n",
    "\n",
    "image_mime_type = \"image/png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c59a1f-94de-4531-80a2-36a2b5b994bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = client.chats.create(model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"Text\", \"Image\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de857847-9902-4cc0-89ab-249ce8e2a9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_part = types.Part(text=f'''\n",
    "    Carefully examine the provided image. Pay attention to the outfit the model is wearing. \n",
    "    Do not generate an image at this point, only inspect the image and tell me what you see.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b353b25-b442-4cab-8255-765f069cf08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_part = types.Part(\n",
    "    inline_data=types.Blob(\n",
    "        mime_type=image_mime_type,\n",
    "        data=B64_BASE_IMAGE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52179c-ba69-4c64-bcd0-0f3da8504dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message_content = [text_part, image_part]\n",
    "\n",
    "chat.send_message(message_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d826726-050f-4227-a0c4-5a65866a1f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_chat_prompt = f'''Generate an image of a woman wearing this exact outfit. \n",
    "Ensure the woman has natural features, such as her face, feet, toes and hands. \n",
    "\n",
    "The image should be high-quality and professionally styled, as if taken by a professional photographer for a magazine.\n",
    "\n",
    "The scene is a trendy fashion show runway, with a large audience seated on both sides.\n",
    "The camera is located at the end of the runway and eye level with the woman\n",
    "The woman is walking toward the camera as she starts her walk down the runway\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3de46d-29ba-4f09-899c-c7ccf84c9844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Generating image. Please wait...\" )\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "response = chat.send_message(start_chat_prompt)\n",
    "\n",
    "# --- Corrected Image and Text Handling ---\n",
    "if response.candidates and response.candidates[0].content:\n",
    "    # Iterate through ALL parts in the response\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        if part.text:  # Check if the part has text\n",
    "            print(\"Model (Text Part):\", part.text)\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "        if part.inline_data:  # Check if the part has inline_data (image)\n",
    "            try:\n",
    "                byte_stream = BytesIO(part.inline_data.data)\n",
    "                gen_image = Image.open(byte_stream)  # Open directly\n",
    "                # gen_image = gen_image.convert(\"RGB\")  # Only convert if you DON'T want alpha\n",
    "                display(gen_image)\n",
    "                print(\"-\" * 20)\n",
    "            except Exception as e:\n",
    "                print(f\"Error displaying image: {e}\")\n",
    "else:\n",
    "     print(\"No candidates or content found in the response.\")\n",
    "print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caddd65-1736-4a09-ae91-3c554252b160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_1 = 'image_1.png'\n",
    "gen_image.save(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d293ad-06c3-498a-a7a2-4903d0017f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_1_uri = upload_file_to_gcs(gcs_bucket, image_1, image_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3fb974-e836-40c5-81e3-c83f63bc84e0",
   "metadata": {},
   "source": [
    "## Generate the fist video clip from the generated image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93462b3-7ee7-4f6f-a141-0d54ce304669",
   "metadata": {},
   "source": [
    "Define prompt to create the first video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245b72f-8598-45cd-814e-b04e067b27bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(image_1, \"rb\") as f:\n",
    "    encoded_base_image = base64.b64encode(f.read())\n",
    "B64_BASE_IMAGE = encoded_base_image.decode('utf-8')\n",
    "\n",
    "image_mime_type = \"image/png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f16782-6804-4ea6-b44b-00ea66c05710",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_generation_prompt = f'''\n",
    "The woman is walking towards the camera\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783827b-ca83-433b-9aab-25c4d34cd7b0",
   "metadata": {},
   "source": [
    "Define the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd395c-6387-4fe8-83a8-b98333860ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "operation = client.models.generate_videos(\n",
    "    model=\"veo-2.0-generate-001\",\n",
    "    prompt=video_generation_prompt,\n",
    "    image=genImage(\n",
    "        #gcs_uri=image_1_uri,\n",
    "        image_bytes=B64_BASE_IMAGE,\n",
    "        mime_type=\"image/png\",\n",
    "    ),\n",
    "    config=GenerateVideosConfig(\n",
    "        aspect_ratio=\"9:16\", # 16:9 (landscape) and 9:16 (portrait) are supported.\n",
    "        number_of_videos=4,\n",
    "        duration_seconds=\"6\",\n",
    "        fps=24,\n",
    "        person_generation=\"allow_adult\",\n",
    "        enhance_prompt=True,\n",
    "        output_gcs_uri=output_gcs_uri,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0c446-add0-4951-ad31-e1beb0c6a5b8",
   "metadata": {},
   "source": [
    "Submit the request and process the resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3a514-a1f9-4451-b1a7-da9f2c21cab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while not operation.done:\n",
    "    time.sleep(15)\n",
    "    operation = client.operations.get(operation)\n",
    "    print(operation)\n",
    "\n",
    "generated_videos_data = [] # Initialize an empty list to store video data\n",
    "\n",
    "if operation.response:\n",
    "    print(\"Processing generated videos...\")\n",
    "    if operation.result and hasattr(operation.result, 'generated_videos'):\n",
    "        for generated_video_obj in operation.result.generated_videos:\n",
    "            if generated_video_obj.video and generated_video_obj.video.uri:\n",
    "                video_uri = generated_video_obj.video.uri\n",
    "                video_name = os.path.basename(video_uri)\n",
    "                \n",
    "                local_file = download_file_from_uri(video_uri, local_tmp_folder_1)\n",
    "\n",
    "                video_info = {\n",
    "                    \"name\": video_name,\n",
    "                    \"uri\": video_uri,\n",
    "                    \"tmp_file\": local_file\n",
    "                    # You could add more info here if available and needed,\n",
    "                    # e.g., duration, mime_type from generated_video_obj.video\n",
    "                }\n",
    "                generated_videos_data.append(video_info)\n",
    "            else:\n",
    "                print(f\"A generated video entry was found but did not have a valid URI. Skipping.\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully extracted data for {len(generated_videos_data)} videos:\")\n",
    "        for video_data in generated_videos_data:\n",
    "            print(f\"  Name: {video_data['name']}, URI: {video_data['uri']}, Local File: {video_data['tmp_file']}\")\n",
    "            video_player = Video(video_data['tmp_file'], embed=True, width=640, height=480)\n",
    "            display(video_player)\n",
    "\n",
    "    else:\n",
    "        print(\"No generated videos found in the response.\")\n",
    "elif operation.error:\n",
    "    error_message = operation.error.message if hasattr(operation.error, 'message') else str(operation.error)\n",
    "    print(f\"Operation failed with error: {error_message}\")\n",
    "else:\n",
    "    print(\"Operation completed but no response or error was found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78ff02-b274-4c6f-a4ea-cf3ee3916c71",
   "metadata": {},
   "source": [
    "Inspect the generated videos to determine the accuracy and quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f39178-198a-4ece-a4bf-dc2988a3e3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_inspect_prompt = f'''\n",
    "    You will be provided with a video along with the associated name local file and GCS URI.\n",
    "    \n",
    "    Judge the accuracy of the generated video based on the input prompt and lifelike motion. \n",
    "    Deduct points for features or actions that were either added, changed or removed from the original prompt.\n",
    "    Deduct additional points for the immediate area around the subject in the image that looks out of place or unrealistic.\n",
    "    Give the image a ranking of 1-10, with 1 being low and 10 being high.\n",
    "\n",
    "    Do not include any greetings or pleasantries in your response.\n",
    "    \n",
    "    The input prompt used to generate this video is:\n",
    "    {video_generation_prompt}\n",
    "    \n",
    "    \n",
    "    Example output:\n",
    "    name: video.mp4\n",
    "    \n",
    "    uri: gs://bucket/folder/file.mp4\n",
    "    \n",
    "    local: ./folder/file.mp4\n",
    "    \n",
    "    qa_score: 5\n",
    "\n",
    "    details: summary of the video\n",
    "\n",
    "    inconsistencies: list of identified problems with the image \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8211c-9530-4c3c-b067-108155ed0834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_client = genai.Client(vertexai=True, project=project_id, location=region, http_options=HttpOptions(api_version=\"v1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d41be-a0da-4ff6-9ce8-9ed9fb2c897c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if generated_videos_data:\n",
    "    best_video_score = -1 # Or some other initial comparison value\n",
    "    best_video_info = None\n",
    "        \n",
    "    vid_chat = vid_client.chats.create(model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"Text\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for video_data in generated_videos_data:\n",
    "        #print(f\"\\nAnalyzing video: {video_data['name']} ({video_data['uri']})\")\n",
    "        \n",
    "        \n",
    "\n",
    "        video_part = Part.from_uri(\n",
    "            file_uri=video_data['uri'],\n",
    "            mime_type=\"video/mp4\",\n",
    "        )\n",
    "\n",
    "       \n",
    "        message_content = [f'''The file name is {video_data['name']} the local file is {video_data['tmp_file']} and the GCS URI is {video_data['uri']}. {video_inspect_prompt}''', video_part]\n",
    "        \n",
    "        response = vid_chat.send_message(message_content)\n",
    "        print('------------------------')\n",
    "        print(response.text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1b1c6-4742-440e-acf0-cf9b27a2955d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = vid_chat.send_message(f'''Based on your analysis, provide the local file path for the best video to use.\n",
    "Only respond with the local file path''')\n",
    "selected_video_1 = response.text\n",
    "print(selected_video_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ef47d-721c-47ef-afe1-b08e94fccbf3",
   "metadata": {},
   "source": [
    "## Extract the last image from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4690da7-2721-4082-9ef0-1a091bb03ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_file = selected_video_1.rstrip()\n",
    "image_file = \"clip_1_end.png\"\n",
    "\n",
    "extract_last_frame(video_file, image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90326d-0402-4163-9363-274b3060e6dd",
   "metadata": {},
   "source": [
    "## Create a second video with Veo based on the last frame of video 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488044b5-26a9-42da-88e2-6f5b06a3a0fa",
   "metadata": {},
   "source": [
    "Use the same veo code as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe6df1-325e-4738-9a45-b6b03797f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_generation_prompt = f'''\n",
    "the woman is turning around\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9fd29-9a37-4a91-bc36-24b1eb3603fc",
   "metadata": {},
   "source": [
    "Define the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716dfb11-f2a6-4cbb-9e0b-580300402786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(image_file, \"rb\") as f:\n",
    "    encoded_base_image = base64.b64encode(f.read())\n",
    "B64_BASE_IMAGE = encoded_base_image.decode('utf-8')\n",
    "\n",
    "image_mime_type = \"image/png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c66cc-7d25-47b5-b2bb-b994c60293b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "operation = client.models.generate_videos(\n",
    "    model=\"veo-2.0-generate-001\",\n",
    "    prompt=video_generation_prompt,\n",
    "    image=genImage(\n",
    "        image_bytes=B64_BASE_IMAGE,\n",
    "        mime_type=\"image/png\",\n",
    "    ),\n",
    "    config=GenerateVideosConfig(\n",
    "        aspect_ratio=\"9:16\", # 16:9 (landscape) and 9:16 (portrait) are supported.\n",
    "        number_of_videos=4,\n",
    "        duration_seconds=\"8\",\n",
    "        fps=24,\n",
    "        person_generation=\"allow_adult\",\n",
    "        enhance_prompt=True,\n",
    "        output_gcs_uri=output_gcs_uri,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21502c8-6876-41f9-b920-35828e526efa",
   "metadata": {},
   "source": [
    "Submit the request and process the resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7690d2-9ac8-48d3-ba8d-a59c56c542b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while not operation.done:\n",
    "    time.sleep(15)\n",
    "    operation = client.operations.get(operation)\n",
    "    print(operation)\n",
    "\n",
    "generated_videos_data = [] # Initialize an empty list to store video data\n",
    "\n",
    "if operation.response:\n",
    "    print(\"Processing generated videos...\")\n",
    "    if operation.result and hasattr(operation.result, 'generated_videos'):\n",
    "        for generated_video_obj in operation.result.generated_videos:\n",
    "            if generated_video_obj.video and generated_video_obj.video.uri:\n",
    "                video_uri = generated_video_obj.video.uri\n",
    "                video_name = os.path.basename(video_uri)\n",
    "                \n",
    "                local_file = download_file_from_uri(video_uri, local_tmp_folder_2)\n",
    "\n",
    "                video_info = {\n",
    "                    \"name\": video_name,\n",
    "                    \"uri\": video_uri,\n",
    "                    \"tmp_file\": local_file\n",
    "                    # You could add more info here if available and needed,\n",
    "                    # e.g., duration, mime_type from generated_video_obj.video\n",
    "                }\n",
    "                generated_videos_data.append(video_info)\n",
    "            else:\n",
    "                print(f\"A generated video entry was found but did not have a valid URI. Skipping.\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully extracted data for {len(generated_videos_data)} videos:\")\n",
    "        for video_data in generated_videos_data:\n",
    "            print(f\"  Name: {video_data['name']}, URI: {video_data['uri']}, Local File: {video_data['tmp_file']}\")\n",
    "            video_player = Video(video_data['tmp_file'], embed=True, width=640, height=480)\n",
    "            display(video_player)\n",
    "\n",
    "    else:\n",
    "        print(\"No generated videos found in the response.\")\n",
    "elif operation.error:\n",
    "    error_message = operation.error.message if hasattr(operation.error, 'message') else str(operation.error)\n",
    "    print(f\"Operation failed with error: {error_message}\")\n",
    "else:\n",
    "    print(\"Operation completed but no response or error was found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c7a34-2d18-4d2d-8a5d-f62ddba45931",
   "metadata": {},
   "source": [
    "Inspect the videos for accuracy and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fb533-035a-4d93-ba40-ee8ecf2bab9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_inspect_prompt = f'''\n",
    "    You will be provided with a video along with the associated name local file and GCS URI.\n",
    "    \n",
    "    Judge the accuracy of the generated video based on the input prompt and lifelike motion. \n",
    "    Deduct points for features or actions that were either added, changed or removed from the original prompt.\n",
    "    Deduct additional points for the immediate area around the subject in the image that looks out of place or unrealistic.\n",
    "    Give the image a ranking of 1-10, with 1 being low and 10 being high.\n",
    "\n",
    "    Do not include any greetings or pleasantries in your response.\n",
    "    \n",
    "    The input prompt used to generate this video is:\n",
    "    {video_generation_prompt}\n",
    "    \n",
    "    \n",
    "    Example output:\n",
    "    name: video.mp4\n",
    "    \n",
    "    uri: gs://bucket/folder/file.mp4\n",
    "    \n",
    "    local: ./folder/file.mp4\n",
    "    \n",
    "    qa_score: 5\n",
    "\n",
    "    details: summary of the video\n",
    "\n",
    "    inconsistencies: list of identified problems with the image \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802f23c-a392-45d6-850c-d0d8b945c215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if generated_videos_data:\n",
    "    best_video_score = -1 # Or some other initial comparison value\n",
    "    best_video_info = None\n",
    "    \n",
    "    vid_chat = vid_client.chats.create(model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"Text\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for video_data in generated_videos_data:\n",
    "        #print(f\"\\nAnalyzing video: {video_data['name']} ({video_data['uri']})\")\n",
    "        \n",
    "        vid_client = genai.Client(vertexai=True, project=project_id, location=region, http_options=HttpOptions(api_version=\"v1\"))\n",
    "\n",
    "        video_part = Part.from_uri(\n",
    "            file_uri=video_data['uri'],\n",
    "            mime_type=\"video/mp4\",\n",
    "        )\n",
    "        \n",
    "        message_content = [f'''The file name is {video_data['name']} the local file is {video_data['tmp_file']} and the GCS URI is {video_data['uri']}. {video_inspect_prompt}''', video_part]\n",
    "        \n",
    "        response = vid_chat.send_message(message_content)\n",
    "        print('------------------------')\n",
    "        print(response.text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea36ba-b89c-47ee-b14e-bbdd27399ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = vid_chat.send_message(f'''Based on your analysis, provide the local file path for the best video to use.\n",
    "Only respond with the local file path''')\n",
    "selected_video_2 = response.text\n",
    "print(selected_video_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c3e0bd-7e8e-4de2-b751-0d4f3b13a4ac",
   "metadata": {},
   "source": [
    "## Extract the last image from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289db9b-3993-4da0-af42-971d153e5171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_file = selected_video_2.rstrip()\n",
    "image_file = \"clip_2_end.png\"\n",
    "\n",
    "extract_last_frame(video_file, image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beace3e4-9133-4b95-9ce2-05c851691d00",
   "metadata": {},
   "source": [
    "## Create a third video with Veo based on the last frame of video 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e94bc-b484-43ac-a592-2ddbbc3b9c20",
   "metadata": {},
   "source": [
    "Use the same veo code as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313f53c-e1b1-4dec-8d30-ecee3fede6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_generation_prompt = f'''\n",
    "The woman walks away from the camera\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be63838-8e7a-4090-aa80-d19fd43d70c0",
   "metadata": {},
   "source": [
    "Define the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28731215-d43c-4efe-84a8-e966b74498ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(image_file, \"rb\") as f:\n",
    "    encoded_base_image = base64.b64encode(f.read())\n",
    "B64_BASE_IMAGE = encoded_base_image.decode('utf-8')\n",
    "\n",
    "image_mime_type = \"image/png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82554c-9380-4072-b450-c657d44ab56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "operation = client.models.generate_videos(\n",
    "    model=\"veo-2.0-generate-001\",\n",
    "    prompt=video_generation_prompt,\n",
    "    image=genImage(\n",
    "        image_bytes=B64_BASE_IMAGE,\n",
    "        mime_type=\"image/png\",\n",
    "    ),\n",
    "    config=GenerateVideosConfig(\n",
    "        aspect_ratio=\"9:16\", # 16:9 (landscape) and 9:16 (portrait) are supported.\n",
    "        number_of_videos=4,\n",
    "        duration_seconds=\"8\",\n",
    "        fps=24,\n",
    "        person_generation=\"allow_adult\",\n",
    "        enhance_prompt=True,\n",
    "        output_gcs_uri=output_gcs_uri,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902be46-ae6e-47fe-8b12-b933439024bb",
   "metadata": {},
   "source": [
    "Submit the request and process the resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb24f1-07a9-4e20-8ab7-9571f46e02d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while not operation.done:\n",
    "    time.sleep(15)\n",
    "    operation = client.operations.get(operation)\n",
    "    print(operation)\n",
    "\n",
    "generated_videos_data = [] # Initialize an empty list to store video data\n",
    "\n",
    "if operation.response:\n",
    "    print(\"Processing generated videos...\")\n",
    "    if operation.result and hasattr(operation.result, 'generated_videos'):\n",
    "        for generated_video_obj in operation.result.generated_videos:\n",
    "            if generated_video_obj.video and generated_video_obj.video.uri:\n",
    "                video_uri = generated_video_obj.video.uri\n",
    "                video_name = os.path.basename(video_uri)\n",
    "                \n",
    "                local_file = download_file_from_uri(video_uri, local_tmp_folder_3)\n",
    "\n",
    "                video_info = {\n",
    "                    \"name\": video_name,\n",
    "                    \"uri\": video_uri,\n",
    "                    \"tmp_file\": local_file\n",
    "                    # You could add more info here if available and needed,\n",
    "                    # e.g., duration, mime_type from generated_video_obj.video\n",
    "                }\n",
    "                generated_videos_data.append(video_info)\n",
    "            else:\n",
    "                print(f\"A generated video entry was found but did not have a valid URI. Skipping.\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully extracted data for {len(generated_videos_data)} videos:\")\n",
    "        for video_data in generated_videos_data:\n",
    "            print(f\"  Name: {video_data['name']}, URI: {video_data['uri']}, Local File: {video_data['tmp_file']}\")\n",
    "            video_player = Video(video_data['tmp_file'], embed=True, width=640, height=480)\n",
    "            display(video_player)\n",
    "\n",
    "    else:\n",
    "        print(\"No generated videos found in the response.\")\n",
    "elif operation.error:\n",
    "    error_message = operation.error.message if hasattr(operation.error, 'message') else str(operation.error)\n",
    "    print(f\"Operation failed with error: {error_message}\")\n",
    "else:\n",
    "    print(\"Operation completed but no response or error was found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94062c78-0a6d-4d7c-a011-7463107a19b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_inspect_prompt = f'''\n",
    "    You will be provided with a video along with the associated name local file and GCS URI.\n",
    "    \n",
    "    Judge the accuracy of the generated video based on the input prompt. \n",
    "    Do not deduct points for photography techniques, like bokeh, Deep and Shallow Depth of Field, etc.\n",
    "    Deduct points for features or actions that were either added, changed or removed from the original prompt.\n",
    "    Deduct additional points for the immediate area around the subject in the image that looks out of place or unrealistic.\n",
    "    Give the image a ranking of 1-10, with 1 being low and 10 being high.\n",
    "\n",
    "    Do not include any greetings or pleasantries in your response.\n",
    "    \n",
    "    The input prompt used to generate this video is:\n",
    "    {video_generation_prompt}\n",
    "    \n",
    "    \n",
    "    Example output:\n",
    "    name: video.mp4\n",
    "    \n",
    "    uri: gs://bucket/folder/file.mp4\n",
    "    \n",
    "    local: ./folder/file.mp4\n",
    "    \n",
    "    qa_score: 5\n",
    "\n",
    "    details: summary of the image\n",
    "\n",
    "    inconsistencies: list of identified problems with the image \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1ad6c-eb1f-4baf-9fce-2aed7507c1ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if generated_videos_data:\n",
    "    best_video_score = -1 # Or some other initial comparison value\n",
    "    best_video_info = None\n",
    "    \n",
    "    vid_chat = vid_client.chats.create(model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"Text\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for video_data in generated_videos_data:\n",
    "        #print(f\"\\nAnalyzing video: {video_data['name']} ({video_data['uri']})\")\n",
    "        \n",
    "        vid_client = genai.Client(vertexai=True, project=project_id, location=region, http_options=HttpOptions(api_version=\"v1\"))\n",
    "\n",
    "        video_part = Part.from_uri(\n",
    "            file_uri=video_data['uri'],\n",
    "            mime_type=\"video/mp4\",\n",
    "        )\n",
    "\n",
    "        \n",
    "        message_content = [f'''The file name is {video_data['name']} the local file is {video_data['tmp_file']} and the GCS URI is {video_data['uri']}. {video_inspect_prompt}''', video_part]\n",
    "        \n",
    "        response = vid_chat.send_message(message_content)\n",
    "        print('------------------------')\n",
    "        print(response.text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbb89d-0317-491c-8bf1-341919c91cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = vid_chat.send_message(f'''Based on your analysis, provide the local file path for the best video to use.\n",
    "Only respond with the local file path''')\n",
    "selected_video_3 = response.text\n",
    "print(selected_video_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5218c-ea84-4d3d-b7b6-b5eac9262095",
   "metadata": {},
   "source": [
    "## Merge the three videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca632a7a-b9ca-4a7d-9d69-e33dc9816522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "vid_clip_1 = selected_video_1.rstrip()\n",
    "vid_clip_2 = selected_video_2.rstrip()\n",
    "vid_clip_3 = selected_video_3.rstrip()\n",
    "output_vid = \"merged.mp4\"\n",
    "\n",
    "# Target dimensions for scaling (optional, set to None to disable scaling)\n",
    "TARGET_WIDTH = 720\n",
    "TARGET_HEIGHT = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819912d9-eb0f-484b-baa4-86816f52bf87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Helper function to process and potentially scale a video clip ---\n",
    "def process_video_clip(filepath, target_width=None, target_height=None):\n",
    "    \"\"\"Creates an ffmpeg input stream, probing and scaling if necessary.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: File not found - {filepath}\")\n",
    "        return None # Return None if file doesn't exist\n",
    "\n",
    "    input_stream = ffmpeg.input(filepath)\n",
    "\n",
    "    if target_width is not None and target_height is not None:\n",
    "        try:\n",
    "            # Probe the video dimensions\n",
    "            print(f\"Probing {os.path.basename(filepath)}...\")\n",
    "            probe = ffmpeg.probe(filepath)\n",
    "            video_stream_info = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
    "\n",
    "            if video_stream_info:\n",
    "                width = int(video_stream_info.get('width', 0))\n",
    "                height = int(video_stream_info.get('height', 0))\n",
    "                print(f\"Detected dimensions for {os.path.basename(filepath)}: {width}x{height}\")\n",
    "\n",
    "                # Scale if not target dimensions\n",
    "                if width != target_width or height != target_height:\n",
    "                    print(f\"Scaling {os.path.basename(filepath)} to {target_width}x{target_height}\")\n",
    "                    input_stream = input_stream.filter('scale', target_width, target_height)\n",
    "                else:\n",
    "                    print(f\"No scaling needed for {os.path.basename(filepath)}.\")\n",
    "            else:\n",
    "                 print(f\"Warning: Could not find video stream information for {os.path.basename(filepath)}. Skipping scaling.\")\n",
    "\n",
    "        except ffmpeg.Error as e:\n",
    "            print(f\"Warning: Error probing {os.path.basename(filepath)}. Skipping scaling. Error: {e.stderr.decode()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: An unexpected error occurred during probing/scaling for {os.path.basename(filepath)}. Skipping scaling. Error: {e}\")\n",
    "\n",
    "    return input_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d8555-ff90-4dbc-ad41-811e4a615817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Processing video clips...\")\n",
    "streams = []\n",
    "\n",
    "stream1 = process_video_clip(vid_clip_1, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "if stream1:\n",
    "    streams.append(stream1)\n",
    "\n",
    "stream2 = process_video_clip(vid_clip_2, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "if stream2:\n",
    "    streams.append(stream2)\n",
    "    \n",
    "stream3 = process_video_clip(vid_clip_3, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "if stream3:\n",
    "    streams.append(stream3)\n",
    "\n",
    "# --- Ensure we have two streams to concatenate ---\n",
    "if len(streams) == 3:\n",
    "    print(\"Concatenating video streams...\")\n",
    "    # --- Concatenate the video streams ---\n",
    "    # v=1: take video streams from inputs\n",
    "    # a=1: take audio streams from inputs (keeps original audio from clips)\n",
    "    # If you want to *discard* audio from the input clips use a=0\n",
    "    #concatenated = ffmpeg.concat(*streams, v=1, a=1) # Use a=1 to keep audio from clips\n",
    "    concatenated = ffmpeg.concat(*streams, v=1, a=0)\n",
    "\n",
    "    # --- Define the output ---\n",
    "    output = ffmpeg.output(concatenated, output_vid)\n",
    "\n",
    "    # --- Run ffmpeg ---\n",
    "    print(f\"Running ffmpeg to create {output_vid}...\")\n",
    "    try:\n",
    "        # Add capture_stderr=True here!\n",
    "        # quiet=False still prints to console, capture_stderr makes it available in the exception\n",
    "        stdout, stderr = ffmpeg.run(output, capture_stdout=True, capture_stderr=True, overwrite_output=True, quiet=False)\n",
    "        # If successful, stderr might still contain warnings, print them if desired\n",
    "        if stderr:\n",
    "             print(\"FFmpeg warnings/stderr (run succeeded):\")\n",
    "             print(stderr.decode())\n",
    "        print(f\"Video successfully created: {output_vid}\")\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"--- Error during ffmpeg execution ---\")\n",
    "        # Check if stderr was captured before trying to decode\n",
    "        if e.stderr:\n",
    "            print(\"FFmpeg stderr output:\")\n",
    "            print(e.stderr.decode())\n",
    "        else:\n",
    "            # This part should ideally not be reached if capture_stderr=True, but handles edge cases\n",
    "            print(\"Could not capture ffmpeg stderr. Check console output above for errors.\")\n",
    "            print(f\"ffmpeg-python exception details: {e}\") # Print the exception itself\n",
    "\n",
    "        # Also print stdout if available, might contain clues\n",
    "        if e.stdout:\n",
    "             print(\"FFmpeg stdout output:\")\n",
    "             print(e.stdout.decode())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected Python error occurred during ffmpeg run: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print the full Python traceback for unexpected errors\n",
    "\n",
    "\n",
    "elif len(streams) == 1:\n",
    "     print(\"Error: Only one valid video stream was processed. Cannot concatenate.\")\n",
    "else:\n",
    "     print(\"Error: No valid video streams were processed. Check input file paths and formats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a005c94-fb2b-4211-9e44-fdd8e455a513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(f\"\"\"\n",
    "<video width=\"75%\" height=\"75%\" controls style=\"transform: scale(0.5); transform-origin: top left;\">\n",
    "  <source src=\"{output_vid}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0639d-aa39-47d3-a5d0-4f3cc572b1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb87c1-75a7-40db-b993-8c29e93b3510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-agent-framework-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-agent-framework-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
